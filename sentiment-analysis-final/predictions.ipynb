{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ef5b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely love this new phone, it's amazing!\n",
      "Predicted emotion: love\n",
      "Predicted category: love\n",
      "\n",
      "Text: The weather today is horrible, I feel so down.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: I'm so excited to start my new job next week!\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I can't believe how rude that customer service was.\n",
      "Predicted emotion: annoyance\n",
      "Predicted category: anger\n",
      "\n",
      "Text: My vacation to Hawaii was the best experience ever.\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I'm really disappointed with the quality of this product.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: The movie was incredibly boring and too long.\n",
      "Predicted emotion: annoyance\n",
      "Predicted category: anger\n",
      "\n",
      "Text: Winning the lottery was a dream come true!\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I feel very sad about the news I just heard.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: The concert last night was absolutely fantastic!\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I am so frustrated with the traffic this morning.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: The food at that restaurant was exceptional.\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I am very anxious about the upcoming exams.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: My friends threw me a surprise party, I was so happy!\n",
      "Predicted emotion: joy\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I hate it when my plans get canceled last minute.\n",
      "Predicted emotion: anger\n",
      "Predicted category: anger\n",
      "\n",
      "Text: Reading that book was an enriching experience.\n",
      "Predicted emotion: admiration\n",
      "Predicted category: happy\n",
      "\n",
      "Text: I feel very content and peaceful right now.\n",
      "Predicted emotion: optimism\n",
      "Predicted category: happy\n",
      "\n",
      "Text: Dealing with that problem was so stressful.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n",
      "Text: I am grateful for all the support I received.\n",
      "Predicted emotion: gratitude\n",
      "Predicted category: happy\n",
      "\n",
      "Text: Losing my wallet made me very upset and anxious.\n",
      "Predicted emotion: sadness\n",
      "Predicted category: sad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the model and tokenizer paths\n",
    "# model_path = \"C:/Users/project/Desktop/sentiment analysis/Final\"\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# # # List of texts to analyze\n",
    "# # texts = [\n",
    "# #     \"I love this new song so much!\",\n",
    "# #     \"This is so frustrating, nothing works as it should!\",\n",
    "# #     \"I'm not sure how to feel about this news.\",\n",
    "# #     \"Wow, that was a fantastic performance!\",\n",
    "# # ]\n",
    "# texts = [\n",
    "#     \"I absolutely love this new phone, it's amazing!\",\n",
    "#     \"The weather today is horrible, I feel so down.\",\n",
    "#     \"I'm so excited to start my new job next week!\",\n",
    "#     \"I can't believe how rude that customer service was.\",\n",
    "#     \"My vacation to Hawaii was the best experience ever.\",\n",
    "#     \"I'm really disappointed with the quality of this product.\",\n",
    "#     \"The movie was incredibly boring and too long.\",\n",
    "#     \"Winning the lottery was a dream come true!\",\n",
    "#     \"I feel very sad about the news I just heard.\",\n",
    "#     \"The concert last night was absolutely fantastic!\",\n",
    "#     \"I am so frustrated with the traffic this morning.\",\n",
    "#     \"The food at that restaurant was exceptional.\",\n",
    "#     \"I am very anxious about the upcoming exams.\",\n",
    "#     \"My friends threw me a surprise party, I was so happy!\",\n",
    "#     \"I hate it when my plans get canceled last minute.\",\n",
    "#     \"Reading that book was an enriching experience.\",\n",
    "#     \"I feel very content and peaceful right now.\",\n",
    "#     \"Dealing with that problem was so stressful.\",\n",
    "#     \"I am grateful for all the support I received.\",\n",
    "#     \"Losing my wallet made me very upset and anxious.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Tokenize the texts\n",
    "# inputs = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "# # Move inputs to the same device as the model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# # Move the model to the device\n",
    "# model.to(device)\n",
    "\n",
    "# # Make predictions\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "# # Apply sigmoid to get probabilities\n",
    "# probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "# # Define the list of emotions\n",
    "# emotions = [\n",
    "#     'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "#     'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "#     'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "#     'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "#     'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "# ]\n",
    "\n",
    "# # Find the emotion with the maximum probability\n",
    "# for i, text in enumerate(texts):\n",
    "#     max_prob_index = np.argmax(probs[i])\n",
    "#     emotion = emotions[max_prob_index]\n",
    "#     max_prob = probs[i][max_prob_index]\n",
    "#     print(f\"Text: {text}\")\n",
    "#     print(f\"Predicted emotion: {emotion}\\n\")\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the model and tokenizer paths\n",
    "model_path = \"C:/Users/project/Desktop/sentiment analysis/Final/model\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# List of texts to analyze\n",
    "texts = [\n",
    "    \"I absolutely love this new phone, it's amazing!\",\n",
    "    \"The weather today is horrible, I feel so down.\",\n",
    "    \"I'm so excited to start my new job next week!\",\n",
    "    \"I can't believe how rude that customer service was.\",\n",
    "    \"My vacation to Hawaii was the best experience ever.\",\n",
    "    \"I'm really disappointed with the quality of this product.\",\n",
    "    \"The movie was incredibly boring and too long.\",\n",
    "    \"Winning the lottery was a dream come true!\",\n",
    "    \"I feel very sad about the news I just heard.\",\n",
    "    \"The concert last night was absolutely fantastic!\",\n",
    "    \"I am so frustrated with the traffic this morning.\",\n",
    "    \"The food at that restaurant was exceptional.\",\n",
    "    \"I am very anxious about the upcoming exams.\",\n",
    "    \"My friends threw me a surprise party, I was so happy!\",\n",
    "    \"I hate it when my plans get canceled last minute.\",\n",
    "    \"Reading that book was an enriching experience.\",\n",
    "    \"I feel very content and peaceful right now.\",\n",
    "    \"Dealing with that problem was so stressful.\",\n",
    "    \"I am grateful for all the support I received.\",\n",
    "    \"Losing my wallet made me very upset and anxious.\"\n",
    "]\n",
    "\n",
    "# Tokenize the texts\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Apply sigmoid to get probabilities\n",
    "probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "# Define the list of emotions\n",
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "# Define the emotion to category mapping\n",
    "emotion_to_category = {\n",
    "    'admiration': 'happy', 'amusement': 'happy', 'approval': 'happy', 'excitement': 'happy',\n",
    "    'gratitude': 'happy', 'joy': 'happy', 'optimism': 'happy', 'pride': 'happy',\n",
    "    'relief': 'happy', 'surprise': 'happy', 'disappointment': 'sad', 'grief': 'sad',\n",
    "    'sadness': 'sad', 'remorse': 'sad', 'embarrassment': 'sad', 'anger': 'anger',\n",
    "    'annoyance': 'anger', 'disapproval': 'anger', 'disgust': 'anger', 'caring': 'love',\n",
    "    'desire': 'love', 'love': 'love', 'confusion': 'fear', 'curiosity': 'fear',\n",
    "    'fear': 'fear', 'nervousness': 'fear', 'realization': 'fear', 'neutral': 'neutral'\n",
    "}\n",
    "\n",
    "# Map the predicted emotion to the broader category and print results\n",
    "for i, text in enumerate(texts):\n",
    "    max_prob_index = np.argmax(probs[i])\n",
    "    emotion = emotions[max_prob_index]\n",
    "    category = emotion_to_category.get(emotion, 'unknown')\n",
    "    max_prob = probs[i][max_prob_index]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted emotion: {emotion}\")\n",
    "    print(f\"Predicted category: {category}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f0cae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4ce676285447ac87b2d5b2c576e9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/168980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7908190ce1d24997b94b710f19559c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5effd45077549628f7d8205c0a8ba93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/168980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73628a55cc749068586577815a9e874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec046a82731e4fb6aa72d3fb12cb0e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/168980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f596ed50047140ec8dc240fc87ec330d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\project\\AppData\\Local\\Temp\\2\\ipykernel_2824\\2008676777.py:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n",
      "C:\\Users\\project\\anaconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\project\\anaconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\project\\anaconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/precision/precision.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\project\\anaconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/recall/recall.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 12:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Accuracy: 0.9469869637996043\n",
      "F1 Score: 0.9488625796159383\n",
      "Precision: 0.9509571009840233\n",
      "Recall: 0.9469869637996043\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the model and tokenizer paths\n",
    "model_path = \"C:/Users/project/Desktop/sentiment analysis/Final\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load the go_emotions dataset\n",
    "ds = load_dataset(\"go_emotions\", \"raw\")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "ds = ds['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "# Define the list of emotions\n",
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "# Map the labels to a list of emotions\n",
    "def map_labels(example):\n",
    "    return {\"labels\": [example[emotion] for emotion in emotions]}\n",
    "\n",
    "ds = ds.map(map_labels)\n",
    "\n",
    "# Tokenize the text data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "cols = ds[\"train\"].column_names\n",
    "cols.remove(\"labels\")\n",
    "ds_enc = ds.map(tokenize_function, batched=True, remove_columns=cols)\n",
    "\n",
    "# Convert labels to float and set the dataset format to torch\n",
    "ds_enc.set_format(\"torch\")\n",
    "ds_enc = ds_enc.map(lambda x: {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"]).rename_column(\"float_labels\", \"labels\")\n",
    "\n",
    "# Define metrics for evaluation\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "precision_metric = load_metric(\"precision\")\n",
    "recall_metric = load_metric(\"recall\")\n",
    "\n",
    "# Compute metrics function\n",
    "def compute_metrics(p):\n",
    "    # Apply sigmoid to get probabilities\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).numpy()\n",
    "    # Apply threshold to get binary predictions\n",
    "    threshold = 0.2\n",
    "    preds = (preds > threshold).astype(int)\n",
    "    \n",
    "    true_labels = p.label_ids\n",
    "    \n",
    "    # Flatten the arrays for metric calculations\n",
    "    preds_flat = preds.flatten()\n",
    "    true_labels_flat = true_labels.flatten()\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=preds_flat, references=true_labels_flat)\n",
    "    f1 = f1_metric.compute(predictions=preds_flat, references=true_labels_flat, average='weighted')\n",
    "    precision = precision_metric.compute(predictions=preds_flat, references=true_labels_flat, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=preds_flat, references=true_labels_flat, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'f1': f1['f1'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall']\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=3e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='logs',            # Directory for storing logs\n",
    "    logging_steps=10,              # Log every 10 steps\n",
    "    save_strategy=\"epoch\"          # Save checkpoint after each epoch\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_enc['train'],\n",
    "    eval_dataset=ds_enc['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"F1 Score: {eval_results['eval_f1']}\")\n",
    "print(f\"Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Recall: {eval_results['eval_recall']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cb45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
